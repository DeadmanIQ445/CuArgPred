{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "diploma.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHL-UeESRkzr"
      },
      "source": [
        "import os\n",
        "import tf_model_modified as tf_model\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from official.modeling import tf_utils\n",
        "from official import nlp\n",
        "from official.nlp import bert\n",
        "from cubert_tokenizer import python_tokenizer, code_to_subtokenized_sentences\n",
        "\n",
        "# Load the required submodules\n",
        "import official.nlp.optimization\n",
        "import official.nlp.bert.bert_models\n",
        "import official.nlp.bert.configs\n",
        "import official.nlp.bert.run_classifier\n",
        "import official.nlp.bert.tokenization\n",
        "import official.nlp.data.classifier_data_lib\n",
        "import official.nlp.modeling.losses\n",
        "import official.nlp.modeling.models\n",
        "import official.nlp.modeling.networks\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "from sklearn import preprocessing\n",
        "import itertools\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qbXzQh6R2FN",
        "outputId": "24527d72-7465-47a4-8585-feb638af6e1d"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "DS_PATH = \"../data/_all_data.csv\"\n",
        "EPOCHS = 3\n",
        "shuffle_buffer_size = 10000\n",
        "SEQ_LENGTH = 512\n",
        "BATCH_SIZE = 2\n",
        "MODEL_PATH = \"../bert2\"\n",
        "FREQ_LIMIT = 200\n",
        "FREQ_CUT_SYMBOL = \"<UNK>\"\n",
        "\n",
        "with open(MODEL_PATH+ \"/cubert_config.json\") as conf_file:\n",
        "    config_dict = json.loads(conf_file.read())\n",
        "    bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
        "\n",
        "bert_encoder = bert.bert_models.get_transformer_encoder(\n",
        "    bert_config, sequence_length=SEQ_LENGTH)\n",
        "bert_encoder.trainable = False\n",
        "checkpoint = tf.train.Checkpoint(model=bert_encoder)\n",
        "checkpoint.restore(MODEL_PATH+'/bert1-1').assert_consumed()\n",
        "\n",
        "if \".json\" in DS_PATH:\n",
        "    data = pd.read_json(DS_PATH)\n",
        "else:\n",
        "    data = pd.read_csv(DS_PATH)\n",
        "\n",
        "tokenizer = python_tokenizer.PythonTokenizer()\n",
        "subword_tokenizer = text_encoder.SubwordTextEncoder(MODEL_PATH + \"/cuvocab.txt\")\n",
        "\n",
        "CLS = subword_tokenizer.encode_without_tokenizing(\"[CLS]\")\n",
        "SEP = subword_tokenizer.encode_without_tokenizing(\"[SEP]\")\n",
        "\n",
        "\n",
        "## Preprocessign arg and labels\n",
        "\n",
        "data['arg_types'] = data['arg_types'].apply(eval)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_labels = pd.DataFrame(data['arg_types'].values.tolist())\n",
        "\n",
        "df_labels[pd.isnull(df_labels)]  = 'NaN'\n",
        "df_labels = df_labels.apply(lambda x: x.mask(x.map(x.value_counts())<FREQ_LIMIT, FREQ_CUT_SYMBOL))\n",
        "\n",
        "enc = preprocessing.LabelEncoder()\n",
        "all_types = df_labels.apply(pd.Series).stack().values\n",
        "enc.fit(all_types)\n",
        "\n",
        "FREQ_CUT_ENC = enc.transform([FREQ_CUT_SYMBOL])\n",
        "\n",
        "df3 = df_labels.apply(enc.transform)\n",
        "data['labels'] = df3.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNQLNlH_n7sM"
      },
      "source": [
        "def train_test_by_repo(data, split=0.75):\n",
        "  train_l, test_l = [], [] \n",
        "  c = 0\n",
        "  train_len = split*len(data)\n",
        "  for name, i in data.groupby(['repo']).count().sample(frac=1).iterrows():\n",
        "    if train_len > c:\n",
        "      train_l.append(name)\n",
        "      c+=i['author']\n",
        "    else:\n",
        "      test_l.append(name)\n",
        "  return data.loc[data['repo'].isin(train_l)], data.loc[data['repo'].isin(train_l)]\n",
        "\n",
        "train_ds, test_ds = train_test_by_repo(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdpDrJ7DR6Im"
      },
      "source": [
        "def transform(code_text):\n",
        "    return CLS+sum(code_to_subtokenized_sentences.code_to_cubert_sentences(\n",
        "        code=code_text,\n",
        "        initial_tokenizer=tokenizer,\n",
        "        subword_tokenizer=subword_tokenizer),[])\n",
        "\n",
        "\n",
        "def process_batch(data_batch):\n",
        "    def process_elem(data_batch_i):\n",
        "        id_list = np.zeros((SEQ_LENGTH))\n",
        "        sentence_line = np.array(transform(data_batch_i['body.1'])[:SEQ_LENGTH-1]+SEP)\n",
        "        le = len(sentence_line)\n",
        "        for label, l_types in zip(eval(data_batch_i['arg_names']), data_batch_i['labels']):\n",
        "          if l_types!=FREQ_CUT_ENC:\n",
        "            label_sub = sum([subword_tokenizer.encode_without_tokenizing(word) for word in tokenizer.tokenize(label)],[])\n",
        "            id_list[tuple(np.where(sentence_line == label_sub[0]))] = l_types\n",
        "        return sentence_line, id_list, le\n",
        "    \n",
        "    ids = [] # ner labels for sequence\n",
        "    full_sentence = [] # here will be the end result of method tokenization\n",
        "    le = []\n",
        "    for _,data_batch_i in data_batch.iterrows():\n",
        "        sentence_line, id_list, length = process_elem(data_batch_i)\n",
        "        full_sentence.append(sentence_line)\n",
        "        ids.append(id_list)\n",
        "        le.append(length)\n",
        "    return full_sentence, ids, le\n",
        "\n",
        "def create_dataset(dataset):\n",
        "  def gen():\n",
        "      for _, data_batch in dataset.groupby(np.arange(len(dataset))//BATCH_SIZE):\n",
        "          if len(data_batch) < BATCH_SIZE: continue # just a placeholder for edge case\n",
        "          full_sentence, ids, le = process_batch(data_batch)\n",
        "          full_sentence = tf.ragged.constant(full_sentence)\n",
        "          full_sentence = full_sentence.to_tensor(default_value=0, shape=[BATCH_SIZE, SEQ_LENGTH])\n",
        "          ids = tf.convert_to_tensor(ids)\n",
        "          yield ({'input_word_ids': full_sentence,\n",
        "              'input_mask': ids > 0,\n",
        "              'input_type_ids': tf.zeros_like(full_sentence),\n",
        "          },ids, le)\n",
        "\n",
        "  return tf.data.Dataset.from_generator(\n",
        "          gen,\n",
        "          ({\"input_word_ids\": tf.int32, \"input_mask\": tf.int32, \"input_type_ids\": tf.int32}, tf.int32, tf.int32),\n",
        "          (\n",
        "              {\n",
        "                  \"input_word_ids\": tf.TensorShape([BATCH_SIZE, SEQ_LENGTH]),\n",
        "                  \"input_mask\": tf.TensorShape([BATCH_SIZE, SEQ_LENGTH]),\n",
        "                  \"input_type_ids\": tf.TensorShape([BATCH_SIZE, SEQ_LENGTH])\n",
        "              },\n",
        "              tf.TensorShape([BATCH_SIZE, SEQ_LENGTH]),\n",
        "              None\n",
        "          ),\n",
        "      )\n",
        "\n",
        "train_dataset = create_dataset(train_ds)\n",
        "test_dataset = create_dataset(test_ds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuRhYh1coUVh",
        "outputId": "bf2f227f-69f8-4f08-b892-bce91212133d"
      },
      "source": [
        "N_CLASSES = len(enc.classes_)\n",
        "N_CLASSES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KHuAyzUSCuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b73a61f-90ec-436a-ce11-6d19c5219a94"
      },
      "source": [
        "model = tf_model.TypePredictor(bert_encoder, num_classes=N_CLASSES)\n",
        "print(tf_model.train(model, train_dataset, test_dataset, epochs=EPOCHS, scorer=precision_recall_fscore_support, learning_rate=0.0003, report_every=100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss = 3.9490065574645996, acc = 0.0, top 5 = 0.25, batch=0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss = 2.685851172022112, acc = 0.38557807785685166, top 5 = 0.6864953719566211, batch=100\n",
            "loss = 2.8380062334653404, acc = 0.38600967903835043, top 5 = 0.6829698833920185, batch=200\n",
            "loss = 2.8046256223901946, acc = 0.36529433444131465, top 5 = 0.7035624760601898, batch=300\n",
            "loss = 2.791319627110922, acc = 0.353062712318837, top 5 = 0.7055009380906205, batch=400\n",
            "loss = 2.648143669759867, acc = 0.37243817482190145, top 5 = 0.7324308220958027, batch=500\n",
            "loss = 2.496346041213827, acc = 0.3986254435057083, top 5 = 0.7558263951066794, batch=600\n",
            "loss = 2.380954907498227, acc = 0.42236420611854125, top 5 = 0.7634279208120607, batch=700\n",
            "loss = 2.359141395907849, acc = 0.42525248639953755, top 5 = 0.7708813087989387, batch=800\n",
            "loss = 2.268474833333325, acc = 0.42948531579926663, top 5 = 0.7915182619898792, batch=900\n",
            "loss = 2.22192658976281, acc = 0.43088826161937444, top 5 = 0.80153669677802, batch=1000\n",
            "loss = 2.200266428838736, acc = 0.43477852854141974, top 5 = 0.8106353233760876, batch=1100\n",
            "loss = 2.126900808440528, acc = 0.4466646780129457, top 5 = 0.8236509251935219, batch=1200\n",
            "loss = 2.100253637106641, acc = 0.4559911286758603, top 5 = 0.8294718130026425, batch=1300\n",
            "loss = 2.0518754774747068, acc = 0.4668038149615286, top 5 = 0.8355460203690837, batch=1400\n",
            "loss = 2.070370339300346, acc = 0.46008241149944085, top 5 = 0.8324440144548657, batch=1500\n",
            "loss = 2.0422555950955057, acc = 0.4679919749472133, top 5 = 0.8365775390145743, batch=1600\n",
            "loss = 1.969436935856499, acc = 0.48936114598830194, top 5 = 0.8431966136954617, batch=1700\n",
            "loss = 1.920711737274653, acc = 0.5009696646058376, top 5 = 0.847519916163884, batch=1800\n",
            "loss = 1.8714539075722785, acc = 0.5132924053033114, top 5 = 0.8522296502144772, batch=1900\n",
            "loss = 1.8610691173499634, acc = 0.5165937250550108, top 5 = 0.8525539411173247, batch=2000\n",
            "loss = 1.838320948450462, acc = 0.5219123712789908, top 5 = 0.8552625344619156, batch=2100\n",
            "loss = 1.803268370842277, acc = 0.528738092373459, top 5 = 0.8590235161828668, batch=2200\n",
            "loss = 1.7769226396718008, acc = 0.5369379989589955, top 5 = 0.8611979967383695, batch=2300\n",
            "loss = 1.7502813220063984, acc = 0.5431070908882875, top 5 = 0.8645726572171679, batch=2400\n",
            "loss = 1.7358441481908569, acc = 0.547391855644312, top 5 = 0.8663734476521409, batch=2500\n",
            "loss = 1.71972478608538, acc = 0.5496455275403431, top 5 = 0.8678029412841769, batch=2600\n",
            "loss = 1.6796646791350855, acc = 0.5585701459468772, top 5 = 0.8716032085159279, batch=2700\n",
            "loss = 1.6670384403335277, acc = 0.560293635359656, top 5 = 0.8731655127636695, batch=2800\n",
            "loss = 1.6637630853101477, acc = 0.5601606767092895, top 5 = 0.8741909642824361, batch=2900\n",
            "loss = 1.685235025224182, acc = 0.5537371543644516, top 5 = 0.8727410498066674, batch=3000\n",
            "loss = 1.6921886886524897, acc = 0.5509979307149343, top 5 = 0.8730508098801368, batch=3100\n",
            "loss = 1.6759241396931308, acc = 0.5546006065779212, top 5 = 0.8746382353797366, batch=3200\n",
            "loss = 1.6678497997146227, acc = 0.5557291454182035, top 5 = 0.8758039146095282, batch=3300\n",
            "loss = 1.6444853963615895, acc = 0.5622859216287506, top 5 = 0.877649823936529, batch=3400\n",
            "loss = 1.6400393262195168, acc = 0.5631692409251489, top 5 = 0.8780293438128315, batch=3500\n",
            "loss = 1.6411019521886292, acc = 0.5611652885329641, top 5 = 0.8790492371247804, batch=3600\n",
            "loss = 1.6311348541900743, acc = 0.560985276548884, top 5 = 0.8810033840266852, batch=3700\n",
            "loss = 1.6253691206561116, acc = 0.5615132021386975, top 5 = 0.8820887169116484, batch=3800\n",
            "loss = 1.6309835497778342, acc = 0.5602728623948486, top 5 = 0.8818385090481204, batch=3900\n",
            "loss = 1.6548576461079805, acc = 0.5538413346787215, top 5 = 0.8801668971249937, batch=4000\n",
            "loss = 1.6301537184508956, acc = 0.5584008396272389, top 5 = 0.8827607321482983, batch=4100\n",
            "loss = 1.6501848495485794, acc = 0.5515852986595766, top 5 = 0.8805517761240486, batch=4200\n",
            "loss = 1.658250022090919, acc = 0.548811824373415, top 5 = 0.8797544626967383, batch=4300\n",
            "loss = 1.6596469271424112, acc = 0.5502197074977488, top 5 = 0.8801256353990785, batch=4400\n",
            "loss = 1.6516383622721595, acc = 0.5534962834987819, top 5 = 0.8815599925716071, batch=4500\n",
            "loss = 1.6705491442371265, acc = 0.5495438968924939, top 5 = 0.8792504672241057, batch=4600\n",
            "loss = 1.6758996799466461, acc = 0.5466540780401762, top 5 = 0.878879101102543, batch=4700\n",
            "loss = 1.6762621740657142, acc = 0.5443845915620408, top 5 = 0.8787940444343716, batch=4800\n",
            "loss = 1.6596115844461656, acc = 0.549044302475251, top 5 = 0.8805087991497178, batch=4900\n",
            "loss = 1.661244182263591, acc = 0.5492815832727018, top 5 = 0.8808421848753483, batch=5000\n",
            "loss = 1.6693541765773257, acc = 0.5487560941057713, top 5 = 0.8800082442357698, batch=5100\n",
            "loss = 1.6704694197662757, acc = 0.5472622492485212, top 5 = 0.8800740557334367, batch=5200\n",
            "loss = 1.6701847870171997, acc = 0.5464176505472517, top 5 = 0.8802311987042823, batch=5300\n",
            "loss = 1.6649341911594162, acc = 0.5477318737742041, top 5 = 0.8809255860998381, batch=5400\n",
            "loss = 1.6710909286318953, acc = 0.5456627108301632, top 5 = 0.8806412380216744, batch=5500\n",
            "loss = 1.6776372767683214, acc = 0.5435796827305673, top 5 = 0.879985643941297, batch=5600\n",
            "loss = 1.688045263650627, acc = 0.5423218912708296, top 5 = 0.8791898383583124, batch=5700\n",
            "loss = 1.6960058536716365, acc = 0.5400446076067279, top 5 = 0.8780955657751417, batch=5800\n",
            "loss = 1.696500180093038, acc = 0.5395523761299615, top 5 = 0.8783939329411499, batch=5900\n",
            "loss = 1.6996295837132207, acc = 0.5381786435506057, top 5 = 0.8782370910309261, batch=6000\n",
            "loss = 1.7012691020065551, acc = 0.5378468979166664, top 5 = 0.8780223856793826, batch=6100\n",
            "loss = 1.6956079845945782, acc = 0.5402908797541384, top 5 = 0.8789946667481147, batch=6200\n",
            "loss = 1.705998348980046, acc = 0.5379071947977501, top 5 = 0.8781185809360812, batch=6300\n",
            "loss = 1.7058238218366355, acc = 0.5366133713093675, top 5 = 0.8785108072594517, batch=6400\n",
            "loss = 1.7030960199576786, acc = 0.5373719133101567, top 5 = 0.8787046664129772, batch=6500\n",
            "loss = 1.7103547761041376, acc = 0.5344024942215656, top 5 = 0.8782674097419929, batch=6600\n",
            "loss = 1.7066357463210908, acc = 0.5350054842656009, top 5 = 0.8789926443746572, batch=6700\n",
            "loss = 1.7051220030691467, acc = 0.5351940810059275, top 5 = 0.8794960047661494, batch=6800\n",
            "loss = 1.7064399290291619, acc = 0.5353891533771052, top 5 = 0.8792052301225923, batch=6900\n",
            "loss = 1.7022413603587814, acc = 0.5369317838062297, top 5 = 0.8795686481914629, batch=7000\n",
            "loss = 1.6925391676617734, acc = 0.5384680476440775, top 5 = 0.880747944559503, batch=7100\n",
            "loss = 1.6783944740166776, acc = 0.542833612232728, top 5 = 0.8819994156777063, batch=7200\n",
            "loss = 1.681670163680139, acc = 0.542668677312366, top 5 = 0.88221788319692, batch=7300\n",
            "loss = 1.6914563160871188, acc = 0.5409080905655899, top 5 = 0.8815403645470362, batch=7400\n",
            "loss = 1.688359619843153, acc = 0.5413501809855704, top 5 = 0.8820016661255161, batch=7500\n",
            "loss = 1.6913291326843625, acc = 0.5408189051645043, top 5 = 0.8816704899129433, batch=7600\n",
            "loss = 1.687618262519098, acc = 0.5410583792935295, top 5 = 0.882085528906948, batch=7700\n",
            "loss = 1.688800648388605, acc = 0.5399447297822402, top 5 = 0.8817286396681484, batch=7800\n",
            "loss = 1.6794145190485836, acc = 0.5422883822360364, top 5 = 0.8827421540562623, batch=7900\n",
            "loss = 1.674594513100807, acc = 0.5435601417833407, top 5 = 0.8834407262835968, batch=8000\n",
            "loss = 1.6795074751301053, acc = 0.5415701460171022, top 5 = 0.8831979914688699, batch=8100\n",
            "loss = 1.681650222828134, acc = 0.5400830604339243, top 5 = 0.8831364977752991, batch=8200\n",
            "loss = 1.6777544112922114, acc = 0.5409955110068388, top 5 = 0.8835171484448597, batch=8300\n",
            "loss = 1.6769789633675163, acc = 0.5406041411175312, top 5 = 0.8837804861802372, batch=8400\n",
            "loss = 1.6760459454172871, acc = 0.5401969513809527, top 5 = 0.8839156730316836, batch=8500\n",
            "loss = 1.6809431141516986, acc = 0.5389477110291345, top 5 = 0.8836064478485214, batch=8600\n",
            "loss = 1.6808289319560643, acc = 0.5396083944321842, top 5 = 0.8834761144050335, batch=8700\n",
            "loss = 1.6696718522959797, acc = 0.5433107411284995, top 5 = 0.8845001101024703, batch=8800\n",
            "loss = 1.658999833180048, acc = 0.546099566955564, top 5 = 0.8855910617755745, batch=8900\n",
            "loss = 1.6499199713411081, acc = 0.5482495508980739, top 5 = 0.8865751349523542, batch=9000\n",
            "loss = 1.6400817246954995, acc = 0.5513303558250915, top 5 = 0.8873686601062653, batch=9100\n",
            "loss = 1.641065018191874, acc = 0.5503386315180594, top 5 = 0.8876788944844813, batch=9200\n",
            "loss = 1.638720809210615, acc = 0.5505577792698357, top 5 = 0.8881412591236336, batch=9300\n",
            "loss = 1.6356728962553468, acc = 0.5508149828565286, top 5 = 0.88881775557222, batch=9400\n",
            "loss = 1.6348308304036099, acc = 0.550640427361998, top 5 = 0.889163677208358, batch=9500\n",
            "loss = 1.6311043191261638, acc = 0.5516345182202363, top 5 = 0.8891082229256473, batch=9600\n",
            "loss = 1.6298648993474139, acc = 0.5515227113029281, top 5 = 0.8894167358994203, batch=9700\n",
            "loss = 1.625773394869555, acc = 0.5523940021962179, top 5 = 0.8895172932979941, batch=9800\n",
            "loss = 1.6267290504086078, acc = 0.5515721038154865, top 5 = 0.8905235986887424, batch=9900\n",
            "loss = 1.629094881966233, acc = 0.5501225481923935, top 5 = 0.8904395838556997, batch=10000\n",
            "loss = 1.6312917898702193, acc = 0.549197090815766, top 5 = 0.8903327924702303, batch=10100\n",
            "loss = 1.6268979713107992, acc = 0.5504040670800748, top 5 = 0.890917772829137, batch=10200\n",
            "loss = 1.6272576355689699, acc = 0.5498584488593912, top 5 = 0.8910948831168991, batch=10300\n",
            "loss = 1.6283969124617073, acc = 0.5493806012798435, top 5 = 0.8911503301741436, batch=10400\n",
            "loss = 1.6282661675581582, acc = 0.5495320924947471, top 5 = 0.8911977036273011, batch=10500\n",
            "loss = 1.6216031697064381, acc = 0.5516536436451495, top 5 = 0.8918995534160651, batch=10600\n",
            "loss = 1.6265933075922498, acc = 0.5512759909695051, top 5 = 0.8915382328071078, batch=10700\n",
            "loss = 1.627699408850633, acc = 0.5510291381337891, top 5 = 0.89186903061616, batch=10800\n",
            "loss = 1.633124955738324, acc = 0.5495823760975136, top 5 = 0.891082665160859, batch=10900\n",
            "loss = 1.6395334525607599, acc = 0.54807561830923, top 5 = 0.8900043220567515, batch=11000\n",
            "loss = 1.6416306053643996, acc = 0.5476746738676253, top 5 = 0.8900009071092656, batch=11100\n",
            "loss = 1.6388768926796555, acc = 0.5481242680650581, top 5 = 0.8904541517956259, batch=11200\n",
            "loss = 1.6411659987755738, acc = 0.5473323124120586, top 5 = 0.8902848803081356, batch=11300\n",
            "loss = 1.6434586196139434, acc = 0.546411405451926, top 5 = 0.8901380085711812, batch=11400\n",
            "loss = 1.639438914571846, acc = 0.5471191385169166, top 5 = 0.89052735984412, batch=11500\n",
            "loss = 1.6418986107355151, acc = 0.5463722686981789, top 5 = 0.8902742899704683, batch=11600\n",
            "loss = 1.641097673284871, acc = 0.5458534832200903, top 5 = 0.8905805870379535, batch=11700\n",
            "loss = 1.6385851309831292, acc = 0.5464442800900966, top 5 = 0.8910217605454677, batch=11800\n",
            "loss = 1.6370309416321478, acc = 0.5462859436359158, top 5 = 0.8911493914155428, batch=11900\n",
            "loss = 1.6260898225497735, acc = 0.5494901482534824, top 5 = 0.8920426629486469, batch=12000\n",
            "loss = 1.62456415369002, acc = 0.5504272231126115, top 5 = 0.8917937492987837, batch=12100\n",
            "loss = 1.621580458804321, acc = 0.5512323234298543, top 5 = 0.8920979293059341, batch=12200\n",
            "loss = 1.6111410648428588, acc = 0.5543345453682657, top 5 = 0.8927986945627706, batch=12300\n",
            "loss = 1.6054419715466883, acc = 0.5564390397956877, top 5 = 0.8932137433426737, batch=12400\n",
            "loss = 1.608666114561577, acc = 0.5558762521229702, top 5 = 0.8928077060912213, batch=12500\n",
            "loss = 1.6099752873442565, acc = 0.5551647076068978, top 5 = 0.8928181598082705, batch=12600\n",
            "loss = 1.6130084517292231, acc = 0.5545278728345963, top 5 = 0.8926052457240498, batch=12700\n",
            "loss = 1.616278069231387, acc = 0.5537729671592192, top 5 = 0.8922208101253244, batch=12800\n",
            "loss = 1.6174810159139745, acc = 0.553636666672188, top 5 = 0.8921857627805768, batch=12900\n",
            "loss = 1.6208128397498371, acc = 0.5538789760830523, top 5 = 0.8919257738203518, batch=13000\n",
            "loss = 1.6209247279945058, acc = 0.5532407230635574, top 5 = 0.8920378180042051, batch=13100\n",
            "loss = 1.6227367406125226, acc = 0.5523290054957988, top 5 = 0.8922489451402619, batch=13200\n",
            "loss = 1.6243198612052996, acc = 0.5521803194988159, top 5 = 0.8921278084807301, batch=13300\n",
            "loss = 1.6244913716748772, acc = 0.5517363976089494, top 5 = 0.8924131334407805, batch=13400\n",
            "loss = 1.6221051843400087, acc = 0.5524304188397514, top 5 = 0.8926014288266998, batch=13500\n",
            "loss = 1.6226322891577958, acc = 0.5527976355880705, top 5 = 0.892621715292486, batch=13600\n",
            "loss = 1.6228504100413006, acc = 0.552845889965151, top 5 = 0.8928270991688947, batch=13700\n",
            "loss = 1.6220226108291287, acc = 0.552801900962101, top 5 = 0.8929241812930245, batch=13800\n",
            "loss = 1.622729092825406, acc = 0.5524382998761975, top 5 = 0.8928850781788197, batch=13900\n",
            "loss = 1.6224603535089175, acc = 0.5531899373328628, top 5 = 0.8927441857136941, batch=14000\n",
            "loss = 1.6227173771494692, acc = 0.5525529837834344, top 5 = 0.8928253189441884, batch=14100\n",
            "loss = 1.6225946200272972, acc = 0.5523488648249215, top 5 = 0.8928217496943066, batch=14200\n",
            "loss = 1.6251484030662997, acc = 0.551568262918931, top 5 = 0.8925961796038069, batch=14300\n",
            "loss = 1.6296712132880593, acc = 0.550685514064382, top 5 = 0.8920645636673332, batch=14400\n",
            "loss = 1.6306337385314513, acc = 0.5502847995133036, top 5 = 0.8919799672078773, batch=14500\n",
            "loss = 1.6319750532038113, acc = 0.550026890587995, top 5 = 0.89201149515558, batch=14600\n",
            "loss = 1.6239190183868417, acc = 0.5523692408685955, top 5 = 0.8926955704705694, batch=14700\n",
            "loss = 1.6228666448454683, acc = 0.5527631980536188, top 5 = 0.892840656710261, batch=14800\n",
            "loss = 1.620443635791905, acc = 0.5533100011039636, top 5 = 0.893126240998152, batch=14900\n",
            "loss = 1.620593147830241, acc = 0.5531227461869143, top 5 = 0.8932005375821457, batch=15000\n",
            "loss = 1.6165501912964568, acc = 0.5537895905896174, top 5 = 0.8936263202651012, batch=15100\n",
            "loss = 1.6166554241854538, acc = 0.5536808184485469, top 5 = 0.8935167732403786, batch=15200\n",
            "loss = 1.6211252230673794, acc = 0.5525353760933256, top 5 = 0.8928989724333992, batch=15300\n",
            "loss = 1.6196225583835226, acc = 0.5529258713293027, top 5 = 0.8931010567497639, batch=15400\n",
            "loss = 1.6202622428537208, acc = 0.5523227996790865, top 5 = 0.8931741112040615, batch=15500\n",
            "loss = 1.6226388385102413, acc = 0.5515256020906739, top 5 = 0.8929646831681793, batch=15600\n",
            "loss = 1.6288247912590292, acc = 0.5498513395862402, top 5 = 0.8923397748006039, batch=15700\n",
            "loss = 1.6241996379084274, acc = 0.5508241248632421, top 5 = 0.8926774732357509, batch=15800\n",
            "loss = 1.6275825885229687, acc = 0.5503506944663017, top 5 = 0.8921021836975744, batch=15900\n",
            "loss = 1.6242437243630188, acc = 0.5517342283500871, top 5 = 0.8922564640231226, batch=16000\n",
            "loss = 1.625770706326906, acc = 0.5513009744209595, top 5 = 0.8922542660584776, batch=16100\n",
            "loss = 1.6244424498694063, acc = 0.5513655204102182, top 5 = 0.892380417572921, batch=16200\n",
            "loss = 1.6226421022635156, acc = 0.5516650977128295, top 5 = 0.8926412551224123, batch=16300\n",
            "loss = 1.6224426203893345, acc = 0.5515358339884502, top 5 = 0.8927891489915314, batch=16400\n",
            "loss = 1.620024444906222, acc = 0.5520417483380908, top 5 = 0.8930861087223383, batch=16500\n",
            "loss = 1.6239447040009225, acc = 0.5513943570395721, top 5 = 0.8925751434418725, batch=16600\n",
            "loss = 1.6234598917666405, acc = 0.5511835693207866, top 5 = 0.8928399763004098, batch=16700\n",
            "loss = 1.6242173439882268, acc = 0.5511042041203538, top 5 = 0.8927766513394434, batch=16800\n",
            "loss = 1.6250980468279135, acc = 0.5508966665962354, top 5 = 0.8929218268364534, batch=16900\n",
            "loss = 1.6272243629919492, acc = 0.5504416857085259, top 5 = 0.8927619295783414, batch=17000\n",
            "loss = 1.6279218924001821, acc = 0.5504165701694846, top 5 = 0.8926456082339272, batch=17100\n",
            "loss = 1.622186862170243, acc = 0.5520928463430311, top 5 = 0.8930429320547889, batch=17200\n",
            "loss = 1.61647844198882, acc = 0.5535826838275483, top 5 = 0.8935554775354766, batch=17300\n",
            "loss = 1.6105006065930876, acc = 0.55500863118687, top 5 = 0.8941082093775907, batch=17400\n",
            "loss = 1.604688371434275, acc = 0.5563160161358238, top 5 = 0.8946410940405913, batch=17500\n",
            "loss = 1.6040203370840944, acc = 0.5562319356809913, top 5 = 0.8948336587550825, batch=17600\n",
            "loss = 1.608017135769198, acc = 0.5553909130676061, top 5 = 0.8945324985636549, batch=17700\n",
            "loss = 1.6052098169794182, acc = 0.5563193804036252, top 5 = 0.8948235403001622, batch=17800\n",
            "loss = 1.6027836738071723, acc = 0.557193569174549, top 5 = 0.8950269113445535, batch=17900\n",
            "loss = 1.5976488952501893, acc = 0.5587296538653935, top 5 = 0.8954298422277128, batch=18000\n",
            "loss = 1.5935196961012064, acc = 0.5602565186396626, top 5 = 0.8956730178992235, batch=18100\n",
            "loss = 1.5940195956858436, acc = 0.5598402596341977, top 5 = 0.8957422875820185, batch=18200\n",
            "loss = 1.5922024358436517, acc = 0.560582046250266, top 5 = 0.8958089342937308, batch=18300\n",
            "loss = 1.5914787538606372, acc = 0.5609871109267512, top 5 = 0.8959629683620576, batch=18400\n",
            "loss = 1.5899820683601211, acc = 0.561270363823441, top 5 = 0.8961368365520066, batch=18500\n",
            "loss = 1.5883066937283297, acc = 0.561746161434363, top 5 = 0.8963928873397353, batch=18600\n",
            "loss = 1.5865917006646175, acc = 0.5618490656390248, top 5 = 0.8967747507426107, batch=18700\n",
            "loss = 1.587947343986718, acc = 0.5616846508647639, top 5 = 0.8967462900617784, batch=18800\n",
            "loss = 1.5860436535193074, acc = 0.5618473163571017, top 5 = 0.8971908485867294, batch=18900\n",
            "loss = 1.5848157184734752, acc = 0.56201156363025, top 5 = 0.8975117231697999, batch=19000\n",
            "loss = 1.5810566034370381, acc = 0.5627088886828855, top 5 = 0.8979742329247163, batch=19100\n",
            "loss = 1.5777992691607718, acc = 0.563199942701942, top 5 = 0.8984780645027324, batch=19200\n",
            "loss = 1.5761893830864697, acc = 0.5634204340458318, top 5 = 0.8987191067323936, batch=19300\n",
            "loss = 1.577434402376483, acc = 0.5631976900890051, top 5 = 0.8984682510583268, batch=19400\n",
            "loss = 1.578536787527173, acc = 0.5628696091960164, top 5 = 0.8983958963204202, batch=19500\n",
            "loss = 1.5752156171336682, acc = 0.5636365656777482, top 5 = 0.8987654298937123, batch=19600\n",
            "loss = 1.576805937573876, acc = 0.5630040789645498, top 5 = 0.8986913535953501, batch=19700\n",
            "loss = 1.57622795123656, acc = 0.5631212714257178, top 5 = 0.8988424063133685, batch=19800\n",
            "loss = 1.5741093401578923, acc = 0.5634089979796496, top 5 = 0.8990257060418092, batch=19900\n",
            "loss = 1.5753960992359946, acc = 0.5630431206596873, top 5 = 0.899138952190784, batch=20000\n",
            "loss = 1.5735589246884727, acc = 0.5631838729426667, top 5 = 0.8993588662525027, batch=20100\n",
            "loss = 1.5750759089514532, acc = 0.5624633736321428, top 5 = 0.8993318306655399, batch=20200\n",
            "loss = 1.5756203920521596, acc = 0.5624731612865348, top 5 = 0.8992912823510246, batch=20300\n",
            "loss = 1.5732371927278632, acc = 0.5633110497688252, top 5 = 0.8995452632290197, batch=20400\n",
            "loss = 1.5723433190803353, acc = 0.5632260706385821, top 5 = 0.8997852160536415, batch=20500\n",
            "loss = 1.5687546686359175, acc = 0.5643283552890294, top 5 = 0.9000607224233069, batch=20600\n",
            "loss = 1.5662609702626134, acc = 0.5650178442156484, top 5 = 0.9004166420485666, batch=20700\n",
            "loss = 1.564881713498461, acc = 0.5654052970509749, top 5 = 0.9005995394747572, batch=20800\n",
            "loss = 1.562571495871392, acc = 0.5658279490694493, top 5 = 0.9008740141056345, batch=20900\n",
            "loss = 1.5646046363048576, acc = 0.5652230900074217, top 5 = 0.9005525504295467, batch=21000\n",
            "loss = 1.5625693957151305, acc = 0.5654568070362886, top 5 = 0.9008842535463406, batch=21100\n",
            "loss = 1.5611251026185382, acc = 0.5656046093825675, top 5 = 0.9010590001325564, batch=21200\n",
            "loss = 1.5632445239194395, acc = 0.5651668006891969, top 5 = 0.9007948265407315, batch=21300\n",
            "loss = 1.5630611803784003, acc = 0.5651594401864873, top 5 = 0.9007478747966987, batch=21400\n",
            "loss = 1.5629127065768766, acc = 0.5653748469381067, top 5 = 0.9007368039131958, batch=21500\n",
            "loss = 1.5628651019434412, acc = 0.5655543255318151, top 5 = 0.9006916858687203, batch=21600\n",
            "loss = 1.5560714418619856, acc = 0.5674886058264804, top 5 = 0.9011533589760887, batch=21700\n",
            "loss = 1.55776760727652, acc = 0.5675425306821114, top 5 = 0.9006593641950609, batch=21800\n",
            "loss = 1.5592568360114558, acc = 0.5672342445530463, top 5 = 0.9005853942655517, batch=21900\n",
            "loss = 1.5587998303327815, acc = 0.5669835505382486, top 5 = 0.9007685349484662, batch=22000\n",
            "loss = 1.5582215482771316, acc = 0.5671525909142091, top 5 = 0.9008389236553486, batch=22100\n",
            "loss = 1.5587185065067835, acc = 0.5667391912769255, top 5 = 0.9009580362329367, batch=22200\n",
            "loss = 1.5589821792877512, acc = 0.566715464354113, top 5 = 0.9010411392347725, batch=22300\n",
            "loss = 1.559721629409583, acc = 0.5664400354655179, top 5 = 0.9009918148974289, batch=22400\n",
            "loss = 1.5579823073589976, acc = 0.566835946927735, top 5 = 0.9010618467327614, batch=22500\n",
            "loss = 1.5585173172079592, acc = 0.5665404777735158, top 5 = 0.9011229702394622, batch=22600\n",
            "loss = 1.556876421030861, acc = 0.5667499018055824, top 5 = 0.9013362222264408, batch=22700\n",
            "loss = 1.5567543636122578, acc = 0.5669500071155446, top 5 = 0.9013739421491607, batch=22800\n",
            "loss = 1.5533853689760388, acc = 0.5678473751716812, top 5 = 0.9015274756537751, batch=22900\n",
            "loss = 1.5512600594416601, acc = 0.5688222204735828, top 5 = 0.9016737500991562, batch=23000\n",
            "loss = 1.5483607216514734, acc = 0.5696763088651418, top 5 = 0.9019518318334951, batch=23100\n",
            "loss = 1.5467002800115541, acc = 0.5699704499944719, top 5 = 0.9021568349621166, batch=23200\n",
            "loss = 1.5456760718611267, acc = 0.5702983931200366, top 5 = 0.902339242886189, batch=23300\n",
            "loss = 1.5465257964884407, acc = 0.5702275436725734, top 5 = 0.9022730014769481, batch=23400\n",
            "loss = 1.5484265252067966, acc = 0.5700039961769438, top 5 = 0.901960493275647, batch=23500\n",
            "loss = 1.5518178631769428, acc = 0.5691604785581394, top 5 = 0.9014229437606207, batch=23600\n",
            "loss = 1.5529094891066075, acc = 0.5686588365446382, top 5 = 0.9014361712482466, batch=23700\n",
            "loss = 1.552157328173627, acc = 0.5685647811034678, top 5 = 0.9017232531825573, batch=23800\n",
            "loss = 1.5495783151770894, acc = 0.569047851828694, top 5 = 0.9020135141026963, batch=23900\n",
            "loss = 1.546800174887129, acc = 0.5696930285825265, top 5 = 0.9022858449190202, batch=24000\n",
            "loss = 1.5485565455203951, acc = 0.5695185572852931, top 5 = 0.9021095385520778, batch=24100\n",
            "loss = 1.5506168468095975, acc = 0.5692563187324594, top 5 = 0.9017386917955259, batch=24200\n",
            "loss = 1.5515041506237797, acc = 0.5690140301482038, top 5 = 0.9016035213359269, batch=24300\n",
            "loss = 1.549940404741405, acc = 0.5693907172889533, top 5 = 0.9017553217499051, batch=24400\n",
            "loss = 1.5484188002804011, acc = 0.5698724154446507, top 5 = 0.901899286921098, batch=24500\n",
            "loss = 1.5484187517636026, acc = 0.5697352302590629, top 5 = 0.9019570954504704, batch=24600\n",
            "loss = 1.5531346710542535, acc = 0.5689853329164543, top 5 = 0.9014613182098252, batch=24700\n",
            "loss = 1.5513899604601589, acc = 0.5693646067397681, top 5 = 0.9015731781134295, batch=24800\n",
            "loss = 1.5540860461633461, acc = 0.5687867083739593, top 5 = 0.9012718348682119, batch=24900\n",
            "loss = 1.5560593594511565, acc = 0.5684478351092227, top 5 = 0.9012676725512355, batch=25000\n",
            "loss = 1.5557917835624036, acc = 0.5683454441329864, top 5 = 0.901517299865826, batch=25100\n",
            "loss = 1.5560104984226053, acc = 0.5685606155628953, top 5 = 0.9015789538359738, batch=25200\n",
            "loss = 1.553056987637995, acc = 0.5694302352988223, top 5 = 0.9018857059213341, batch=25300\n",
            "loss = 1.5516483571440327, acc = 0.5699843605527901, top 5 = 0.9019700518728409, batch=25400\n",
            "loss = 1.549710008593599, acc = 0.5704055485614914, top 5 = 0.9022019632342255, batch=25500\n",
            "loss = 1.547380187620936, acc = 0.5709882266206546, top 5 = 0.9025283545526799, batch=25600\n",
            "loss = 1.5463879484421053, acc = 0.5710474949335552, top 5 = 0.9027751290441364, batch=25700\n",
            "loss = 1.5453055365838486, acc = 0.5710798902586696, top 5 = 0.9030569886834774, batch=25800\n",
            "loss = 1.5463600053787623, acc = 0.5708187740354211, top 5 = 0.9030388313124325, batch=25900\n",
            "loss = 1.5436153472006924, acc = 0.5715670296894995, top 5 = 0.9033078637909808, batch=26000\n",
            "loss = 1.5435395736501463, acc = 0.5715752676343708, top 5 = 0.9033116288013837, batch=26100\n",
            "loss = 1.5462971451120684, acc = 0.570891318643664, top 5 = 0.9030258089214458, batch=26200\n",
            "loss = 1.5466076568466556, acc = 0.5707967331862067, top 5 = 0.902976374587419, batch=26300\n",
            "loss = 1.5454527289108508, acc = 0.5712094650146228, top 5 = 0.9030885014477544, batch=26400\n",
            "loss = 1.5438438211236802, acc = 0.5713489670460423, top 5 = 0.9032698167919968, batch=26500\n",
            "loss = 1.5439102448788788, acc = 0.5713029483550915, top 5 = 0.9033813475564643, batch=26600\n",
            "loss = 1.5436513219189218, acc = 0.5711959943776843, top 5 = 0.9034555141075163, batch=26700\n",
            "loss = 1.5436979334867682, acc = 0.5709794014719998, top 5 = 0.9034389583772447, batch=26800\n",
            "loss = 1.5459836163489378, acc = 0.5704296767165993, top 5 = 0.903139570138591, batch=26900\n",
            "loss = 1.5459111383363933, acc = 0.5701584283764077, top 5 = 0.9033589905439173, batch=27000\n",
            "loss = 1.5511274966619009, acc = 0.5693809301888089, top 5 = 0.9028261294839527, batch=27100\n",
            "loss = 1.5510211188855687, acc = 0.5695241805746369, top 5 = 0.9027795358699756, batch=27200\n",
            "loss = 1.5496693798156285, acc = 0.5694216014346413, top 5 = 0.9030433736554514, batch=27300\n",
            "loss = 1.5504952961758196, acc = 0.569294121922837, top 5 = 0.9030499473784538, batch=27400\n",
            "loss = 1.551594034505467, acc = 0.5689660136992837, top 5 = 0.9029669202772683, batch=27500\n",
            "loss = 1.5515400094774574, acc = 0.5687586625763992, top 5 = 0.9030257069992637, batch=27600\n",
            "loss = 1.551063816619367, acc = 0.5687475428178965, top 5 = 0.9031324629857412, batch=27700\n",
            "loss = 1.5509174940531043, acc = 0.5688213540877938, top 5 = 0.9031940696727572, batch=27800\n",
            "loss = 1.5515278670882595, acc = 0.5686433074391176, top 5 = 0.9032244556312775, batch=27900\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}