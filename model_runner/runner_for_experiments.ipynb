{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/deadman445/venvs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5039: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "         0     1     2     3     4     5     6     7     8     9   ...    51  \\\n",
      "0      dict  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "1      Task  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "2  datetime  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "3  datetime  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "4      Task  None  None  None  None  None  None  None  None  None  ...  None   \n",
      "\n",
      "     52    53    54    55    56    57    58    59    60  \n",
      "0  None  None  None  None  None  None  None  None  None  \n",
      "1  None  None  None  None  None  None  None  None  None  \n",
      "2  None  None  None  None  None  None  None  None  None  \n",
      "3  None  None  None  None  None  None  None  None  None  \n",
      "4  None  None  None  None  None  None  None  None  None  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "from cubert_tokenizer import python_tokenizer, code_to_subtokenized_sentences\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "\n",
    "MAX_ARG_LENGTH =20\n",
    "DS_PATH = \"../data/_all_data.csv\"\n",
    "EPOCHS = 3\n",
    "shuffle_buffer_size = 1000\n",
    "SEQ_LENGTH = 512\n",
    "\n",
    "bert_tokenizer = bert.tokenization.FullTokenizer(\n",
    "    vocab_file=\"../bert2/cuvocab.txt\",\n",
    "     do_lower_case=True)\n",
    "\n",
    "with open(\"../bert2/cubert_config.json\") as conf_file:\n",
    "    config_dict = json.loads(conf_file.read())\n",
    "    bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
    "\n",
    "bert_encoder = bert.bert_models.get_transformer_encoder(\n",
    "    bert_config, sequence_length=SEQ_LENGTH)\n",
    "\n",
    "tf.keras.utils.plot_model(bert_encoder, show_shapes=True, dpi=48)\n",
    "# tf.keras.utils.plot_model(bert_classifier, show_shapes=True, dpi=48)\n",
    "\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model=bert_encoder)\n",
    "checkpoint.restore('../bert2/bert1-1').assert_consumed()\n",
    "if \".json\" in DS_PATH:\n",
    "    data = pd.read_json(DS_PATH)\n",
    "else:\n",
    "    data = pd.read_csv(DS_PATH)\n",
    "\n",
    "tokenizer = python_tokenizer.PythonTokenizer()\n",
    "subword_tokenizer = text_encoder.SubwordTextEncoder(\"../bert2/cuvocab.txt\")\n",
    "\n",
    "data_body1 = data['body.1']\n",
    "\n",
    "## Preprocessign arg\n",
    "\n",
    "data['arg_types'] = data['arg_types'].apply(eval)\n",
    "df_labels = pd.DataFrame(data['arg_types'].values.tolist())\n",
    "\n",
    "print(df_labels.head())\n",
    "\n",
    "max_label_length=10\n",
    "df_labels2=df_labels.iloc[:,0:max_label_length]\n",
    "df_labels2[pd.isnull(df_labels2)]  = 'NaN'\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "all_types = df_labels.apply(pd.Series).stack().values\n",
    "enc.fit(all_types)\n",
    "\n",
    "df3 = df_labels2.apply(enc.transform)\n",
    "data['labels'] = df3.values.tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False]])>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tf.sequence_mask([123], 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb_result = mlb.fit_transform(df_labels2.values)\n",
    "df3 = pd.DataFrame(mlb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           author  repo                                               file  \\\n",
       "0       Fongshway  twpm  ./cloner_output/Fongshway__twpm/twpm/hook_runn...   \n",
       "1       Fongshway  twpm  ./cloner_output/Fongshway__twpm/twpm/hooks/exa...   \n",
       "2       Fongshway  twpm  ./cloner_output/Fongshway__twpm/twpm/hooks/def...   \n",
       "3       Fongshway  twpm  ./cloner_output/Fongshway__twpm/twpm/hooks/def...   \n",
       "4       Fongshway  twpm  ./cloner_output/Fongshway__twpm/twpm/hooks/def...   \n",
       "...           ...   ...                                                ...   \n",
       "125716  WIPACrepo   lta  ./cloner_output/WIPACrepo__lta/tests/test_loca...   \n",
       "125717  WIPACrepo   lta  ./cloner_output/WIPACrepo__lta/tests/test_pick...   \n",
       "125718  WIPACrepo   lta  ./cloner_output/WIPACrepo__lta/tests/test_pick...   \n",
       "125719  WIPACrepo   lta  ./cloner_output/WIPACrepo__lta/resources/rucio...   \n",
       "125720  WIPACrepo   lta  ./cloner_output/WIPACrepo__lta/resources/rucio...   \n",
       "\n",
       "                                 has_type  body               name  \\\n",
       "0       https://github.com/Fongshway/twpm  True          to output   \n",
       "1       https://github.com/Fongshway/twpm  True               main   \n",
       "2       https://github.com/Fongshway/twpm  True  be local midnight   \n",
       "3       https://github.com/Fongshway/twpm  True   set default time   \n",
       "4       https://github.com/Fongshway/twpm  True               main   \n",
       "...                                   ...   ...                ...   \n",
       "125716   https://github.com/WIPACrepo/lta  True         gen record   \n",
       "125717   https://github.com/WIPACrepo/lta  True           gen file   \n",
       "125718   https://github.com/WIPACrepo/lta  True         gen record   \n",
       "125719   https://github.com/WIPACrepo/lta  True     print response   \n",
       "125720   https://github.com/WIPACrepo/lta  True          rucio get   \n",
       "\n",
       "                                                docstring  \\\n",
       "0       convert serialize task representation taskwarr...   \n",
       "1       example hook entry point param task task insta...   \n",
       "2       helper function evaluate whether dateime midni...   \n",
       "3       helper function set default timestamp give dat...   \n",
       "4       default time hook entry point param task task ...   \n",
       "...                                                   ...   \n",
       "125716                                                NaN   \n",
       "125717                                                NaN   \n",
       "125718                                                NaN   \n",
       "125719            print interesting thing response object   \n",
       "125720                         query rucio print response   \n",
       "\n",
       "                                               func_descr  \\\n",
       "0       convert serialize task representation taskwarr...   \n",
       "1                                example hook entry point   \n",
       "2       helper function evaluate whether dateime midni...   \n",
       "3       helper function set default timestamp give dat...   \n",
       "4                           default time hook entry point   \n",
       "...                                                   ...   \n",
       "125716                                                NaN   \n",
       "125717                                                NaN   \n",
       "125718                                                NaN   \n",
       "125719            print interesting thing response object   \n",
       "125720                         query rucio print response   \n",
       "\n",
       "                    arg_names             arg_types          arg_descrs  \\\n",
       "0                    ['task']                [dict]  ['serialize task']   \n",
       "1                    ['task']                [Task]   ['task instance']   \n",
       "2               ['timestamp']            [datetime]                ['']   \n",
       "3               ['timestamp']            [datetime]                ['']   \n",
       "4                    ['task']                [Task]   ['task instance']   \n",
       "...                       ...                   ...                 ...   \n",
       "125716                  ['i']                 [int]                ['']   \n",
       "125717                  ['i']                 [int]                ['']   \n",
       "125718                  ['i']                 [int]                ['']   \n",
       "125719  ['title', 'response']  [str, RucioResponse]            ['', '']   \n",
       "125720        ['rc', 'route']    [RucioClient, str]            ['', '']   \n",
       "\n",
       "                                              return_type  \\\n",
       "0                                                     str   \n",
       "1                                                    None   \n",
       "2                                                    bool   \n",
       "3                                                datetime   \n",
       "4                                                    None   \n",
       "...                                                   ...   \n",
       "125716  Dict[str, Union[int, str, Dict[str, str], List...   \n",
       "125717                                     Dict[str, str]   \n",
       "125718  Dict[str, Union[int, str, Dict[str, str], List...   \n",
       "125719                                               None   \n",
       "125720                                               None   \n",
       "\n",
       "                                              return_expr  \\\n",
       "0                            ['json dump task separator']   \n",
       "1                                                      []   \n",
       "2           ['timestamp astimezone tz tzlocal time time']   \n",
       "3       ['timestamp replace hour default time hour min...   \n",
       "4                                    ['return', 'return']   \n",
       "...                                                   ...   \n",
       "125716  ['logical name f data exp ice cube filter pf f...   \n",
       "125717  ['logical name f data exp ice cube filter pf f...   \n",
       "125718  ['logical name f data exp ice cube filter pf f...   \n",
       "125719                                                 []   \n",
       "125720                                                 []   \n",
       "\n",
       "                                           return_descr  \\\n",
       "0                                      taskwarrior json   \n",
       "1                                                  none   \n",
       "2       boolean indicating datetime midnight local time   \n",
       "3         datetime hour minute second value set default   \n",
       "4                                                  none   \n",
       "...                                                 ...   \n",
       "125716                                              NaN   \n",
       "125717                                              NaN   \n",
       "125718                                              NaN   \n",
       "125719                                              NaN   \n",
       "125720                                              NaN   \n",
       "\n",
       "                                                   body.1  \\\n",
       "0           @staticmethod\\n    def to_output(task: dic...   \n",
       "1       def main(task: Task) -> None:\\n    \"\"\"\\n    ex...   \n",
       "2       def is_local_midnight(timestamp: datetime) -> ...   \n",
       "3       def set_default_time(timestamp: datetime) -> d...   \n",
       "4       def main(task: Task) -> None:\\n    # pylint: d...   \n",
       "...                                                   ...   \n",
       "125716      def gen_record(i: int) -> Dict[str, Union[...   \n",
       "125717      def gen_file(i: int) -> Dict[str, str]:\\n ...   \n",
       "125718      def gen_record(i: int) -> Dict[str, Union[...   \n",
       "125719  def print_response(title: str, response: Rucio...   \n",
       "125720  async def rucio_get(rc: RucioClient, route: st...   \n",
       "\n",
       "                                               args_occur  arg_names_len  \\\n",
       "0                                         ['v task item']              1   \n",
       "1       ['original task description task description o...              1   \n",
       "2                                                      []              1   \n",
       "3                                                      []              1   \n",
       "4       ['task due date task get task due task wait da...              1   \n",
       "...                                                   ...            ...   \n",
       "125716                                                 []              1   \n",
       "125717                                                 []              1   \n",
       "125718                                                 []              1   \n",
       "125719            ['print title', 'dump response indent']              2   \n",
       "125720  ['await rc get', 'get route print response rou...              2   \n",
       "\n",
       "        arg_types_len                                             labels  \n",
       "0                   1  [14890, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "1                   1  [11429, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "2                   1  [14848, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "3                   1  [14848, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "4                   1  [11429, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "...               ...                                                ...  \n",
       "125716              1  [15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "125717              1  [15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "125718              1  [15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...  \n",
       "125719              2  [16099, 10062, 7480, 7480, 7480, 7480, 7480, 7...  \n",
       "125720              2  [10061, 16099, 7480, 7480, 7480, 7480, 7480, 7...  \n",
       "\n",
       "[125721 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>repo</th>\n      <th>file</th>\n      <th>has_type</th>\n      <th>body</th>\n      <th>name</th>\n      <th>docstring</th>\n      <th>func_descr</th>\n      <th>arg_names</th>\n      <th>arg_types</th>\n      <th>arg_descrs</th>\n      <th>return_type</th>\n      <th>return_expr</th>\n      <th>return_descr</th>\n      <th>body.1</th>\n      <th>args_occur</th>\n      <th>arg_names_len</th>\n      <th>arg_types_len</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fongshway</td>\n      <td>twpm</td>\n      <td>./cloner_output/Fongshway__twpm/twpm/hook_runn...</td>\n      <td>https://github.com/Fongshway/twpm</td>\n      <td>True</td>\n      <td>to output</td>\n      <td>convert serialize task representation taskwarr...</td>\n      <td>convert serialize task representation taskwarr...</td>\n      <td>['task']</td>\n      <td>[dict]</td>\n      <td>['serialize task']</td>\n      <td>str</td>\n      <td>['json dump task separator']</td>\n      <td>taskwarrior json</td>\n      <td>@staticmethod\\n    def to_output(task: dic...</td>\n      <td>['v task item']</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[14890, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fongshway</td>\n      <td>twpm</td>\n      <td>./cloner_output/Fongshway__twpm/twpm/hooks/exa...</td>\n      <td>https://github.com/Fongshway/twpm</td>\n      <td>True</td>\n      <td>main</td>\n      <td>example hook entry point param task task insta...</td>\n      <td>example hook entry point</td>\n      <td>['task']</td>\n      <td>[Task]</td>\n      <td>['task instance']</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>none</td>\n      <td>def main(task: Task) -&gt; None:\\n    \"\"\"\\n    ex...</td>\n      <td>['original task description task description o...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[11429, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Fongshway</td>\n      <td>twpm</td>\n      <td>./cloner_output/Fongshway__twpm/twpm/hooks/def...</td>\n      <td>https://github.com/Fongshway/twpm</td>\n      <td>True</td>\n      <td>be local midnight</td>\n      <td>helper function evaluate whether dateime midni...</td>\n      <td>helper function evaluate whether dateime midni...</td>\n      <td>['timestamp']</td>\n      <td>[datetime]</td>\n      <td>['']</td>\n      <td>bool</td>\n      <td>['timestamp astimezone tz tzlocal time time']</td>\n      <td>boolean indicating datetime midnight local time</td>\n      <td>def is_local_midnight(timestamp: datetime) -&gt; ...</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[14848, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Fongshway</td>\n      <td>twpm</td>\n      <td>./cloner_output/Fongshway__twpm/twpm/hooks/def...</td>\n      <td>https://github.com/Fongshway/twpm</td>\n      <td>True</td>\n      <td>set default time</td>\n      <td>helper function set default timestamp give dat...</td>\n      <td>helper function set default timestamp give dat...</td>\n      <td>['timestamp']</td>\n      <td>[datetime]</td>\n      <td>['']</td>\n      <td>datetime</td>\n      <td>['timestamp replace hour default time hour min...</td>\n      <td>datetime hour minute second value set default</td>\n      <td>def set_default_time(timestamp: datetime) -&gt; d...</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[14848, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fongshway</td>\n      <td>twpm</td>\n      <td>./cloner_output/Fongshway__twpm/twpm/hooks/def...</td>\n      <td>https://github.com/Fongshway/twpm</td>\n      <td>True</td>\n      <td>main</td>\n      <td>default time hook entry point param task task ...</td>\n      <td>default time hook entry point</td>\n      <td>['task']</td>\n      <td>[Task]</td>\n      <td>['task instance']</td>\n      <td>None</td>\n      <td>['return', 'return']</td>\n      <td>none</td>\n      <td>def main(task: Task) -&gt; None:\\n    # pylint: d...</td>\n      <td>['task due date task get task due task wait da...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[11429, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>125716</th>\n      <td>WIPACrepo</td>\n      <td>lta</td>\n      <td>./cloner_output/WIPACrepo__lta/tests/test_loca...</td>\n      <td>https://github.com/WIPACrepo/lta</td>\n      <td>True</td>\n      <td>gen record</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['i']</td>\n      <td>[int]</td>\n      <td>['']</td>\n      <td>Dict[str, Union[int, str, Dict[str, str], List...</td>\n      <td>['logical name f data exp ice cube filter pf f...</td>\n      <td>NaN</td>\n      <td>def gen_record(i: int) -&gt; Dict[str, Union[...</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>125717</th>\n      <td>WIPACrepo</td>\n      <td>lta</td>\n      <td>./cloner_output/WIPACrepo__lta/tests/test_pick...</td>\n      <td>https://github.com/WIPACrepo/lta</td>\n      <td>True</td>\n      <td>gen file</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['i']</td>\n      <td>[int]</td>\n      <td>['']</td>\n      <td>Dict[str, str]</td>\n      <td>['logical name f data exp ice cube filter pf f...</td>\n      <td>NaN</td>\n      <td>def gen_file(i: int) -&gt; Dict[str, str]:\\n ...</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>125718</th>\n      <td>WIPACrepo</td>\n      <td>lta</td>\n      <td>./cloner_output/WIPACrepo__lta/tests/test_pick...</td>\n      <td>https://github.com/WIPACrepo/lta</td>\n      <td>True</td>\n      <td>gen record</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['i']</td>\n      <td>[int]</td>\n      <td>['']</td>\n      <td>Dict[str, Union[int, str, Dict[str, str], List...</td>\n      <td>['logical name f data exp ice cube filter pf f...</td>\n      <td>NaN</td>\n      <td>def gen_record(i: int) -&gt; Dict[str, Union[...</td>\n      <td>[]</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[15209, 7480, 7480, 7480, 7480, 7480, 7480, 74...</td>\n    </tr>\n    <tr>\n      <th>125719</th>\n      <td>WIPACrepo</td>\n      <td>lta</td>\n      <td>./cloner_output/WIPACrepo__lta/resources/rucio...</td>\n      <td>https://github.com/WIPACrepo/lta</td>\n      <td>True</td>\n      <td>print response</td>\n      <td>print interesting thing response object</td>\n      <td>print interesting thing response object</td>\n      <td>['title', 'response']</td>\n      <td>[str, RucioResponse]</td>\n      <td>['', '']</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>def print_response(title: str, response: Rucio...</td>\n      <td>['print title', 'dump response indent']</td>\n      <td>2</td>\n      <td>2</td>\n      <td>[16099, 10062, 7480, 7480, 7480, 7480, 7480, 7...</td>\n    </tr>\n    <tr>\n      <th>125720</th>\n      <td>WIPACrepo</td>\n      <td>lta</td>\n      <td>./cloner_output/WIPACrepo__lta/resources/rucio...</td>\n      <td>https://github.com/WIPACrepo/lta</td>\n      <td>True</td>\n      <td>rucio get</td>\n      <td>query rucio print response</td>\n      <td>query rucio print response</td>\n      <td>['rc', 'route']</td>\n      <td>[RucioClient, str]</td>\n      <td>['', '']</td>\n      <td>None</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>async def rucio_get(rc: RucioClient, route: st...</td>\n      <td>['await rc get', 'get route print response rou...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>[10061, 16099, 7480, 7480, 7480, 7480, 7480, 7...</td>\n    </tr>\n  </tbody>\n</table>\n<p>125721 rows Ã— 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n    @staticmethod\n    def to_output(task: dict) -> str:\n        \"\"\"\n        Convert serialized task representation to Taskwarrior JSON hook output\n        format.\n\n        :param task: serialized task\n        :return: Taskwarrior JSON\n        \"\"\"\n        fields = Task.FIELDS.copy()\n\n        for k, v in task.items():\n            field_type = fields.get(k, None)\n            if isinstance(field_type, ArrayField) and not isinstance(field_type, AnnotationArrayField):\n                task[k] = ','.join(v)\n\n        return json.dumps(task, separators=(',', ':'))\n[    2    34    66   163  1527    15    43   253   432    20  1115    25\n   210    19  1716   148    25    15    34    45    86    35    26    63\n  3994    17 24350    17  1449    17  4070    17    75    17 28645 21947\n 26414   180    17  2058    17  8861    17   530    35    26    63   597\n    33    35    26    35    26    63    42   280    17  1449    42    17\n 24350    17  1449    35    26    63    42   393    42    17 28645 21947\n 26414   180    17  2058    35    26    63    95    15   504    24  3858\n    21 15458    21   878    20    19    15    10    82   341    16   337\n    68  1115    21   524    20    19    25    15    34    62  1502   142\n    24   504    21   157    20   341    16    70    19    15    46   472\n    20  1502   142    16  2009   256    19   202   126   472    20  1502\n   142    16 17844  2009   256    19    25    15    34   100  1115    31\n   341    30    24  1602    21   230    20   337    19    15    10     7\n     7    60   361    21  1520    20  1115    16 31172    24    20  1602\n    16  2710    19    19     7     7    15     3] task 10\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'input_word_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "  array([[    2,    34,    66,   163,  1527,    15,    43,   253,   432,\n",
       "             20,  1115,    25,   210,    19,  1716,   148,    25,    15,\n",
       "             34,    45,    86,    35,    26,    63,  3994,    17, 24350,\n",
       "             17,  1449,    17,  4070,    17,    75,    17, 28645, 21947,\n",
       "          26414,   180,    17,  2058,    17,  8861,    17,   530,    35,\n",
       "             26,    63,   597,    33,    35,    26,    35,    26,    63,\n",
       "             42,   280,    17,  1449,    42,    17, 24350,    17,  1449,\n",
       "             35,    26,    63,    42,   393,    42,    17, 28645, 21947,\n",
       "          26414,   180,    17,  2058,    35,    26,    63,    95,    15,\n",
       "            504,    24,  3858,    21, 15458,    21,   878,    20,    19,\n",
       "             15,    10,    82,   341,    16,   337,    68,  1115,    21,\n",
       "            524,    20,    19,    25,    15,    34,    62,  1502,   142,\n",
       "             24,   504,    21,   157,    20,   341,    16,    70,    19,\n",
       "             15,    46,   472,    20,  1502,   142,    16,  2009,   256,\n",
       "             19,   202,   126,   472,    20,  1502,   142,    16, 17844,\n",
       "           2009,   256,    19,    25,    15,    34,   100,  1115,    31,\n",
       "            341,    30,    24,  1602,    21,   230,    20,   337,    19,\n",
       "             15,    10,     7,     7,    60,   361,    21,  1520,    20,\n",
       "           1115,    16, 31172,    24,    20,  1602,    16,  2710,    19,\n",
       "             19,     7,     7,    15,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "        dtype=int32)>,\n",
       "  'input_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       "  'input_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       "  'lens': 125721,\n",
       "  'id_list': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([10], dtype=int32)>},\n",
       " <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       " array([[14890,  7480,  7480,  7480,  7480,  7480,  7480,  7480,  7480,\n",
       "          7480]], dtype=int32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "def transform_labels(df_labels_batch):\n",
    "    df_labels = pd.DataFrame(df_labels_batch['arg_types'].values.tolist())\n",
    "    df_labels[pd.isnull(df_labels_batch)] = 'NaN'\n",
    "    df_labels = df_labels.apply(enc.transform)\n",
    "    return mlb.transform(df_labels.values)\n",
    "\n",
    "def transform(code_text):\n",
    "    print(code_text)\n",
    "    return [2]+sum(code_to_subtokenized_sentences.code_to_cubert_sentences(\n",
    "        code=code_text,\n",
    "        initial_tokenizer=tokenizer,\n",
    "        subword_tokenizer=subword_tokenizer),[])\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "MAX_BODY_LENGTH = 64\n",
    "def gen():\n",
    "    for _, data_batch in data.groupby(np.arange(len(data))//batch_size):\n",
    "        if len(data_batch) < batch_size:\n",
    "            continue\n",
    "        ids = []\n",
    "        sentence1 = []\n",
    "        for _,data_batch_i in data_batch.iterrows():\n",
    "            id_list = []\n",
    "            sentence2 = np.array(transform(data_batch_i['body.1'])[:SEQ_LENGTH-1]+[3])\n",
    "            for label in eval(data_batch_i['arg_names']):\n",
    "                print(sentence2, label, np.where(sentence2 == subword_tokenizer.encode(label)[0])[0][0])\n",
    "                id_list.append( np.where(sentence2 == subword_tokenizer.encode(label)[0])[0][0])\n",
    "            sentence1.append(sentence2)\n",
    "        sentence1 = tf.ragged.constant(sentence1)\n",
    "        sentence1 = sentence1.to_tensor(default_value=0, shape=[batch_size, SEQ_LENGTH])\n",
    "        id_list =  tf.convert_to_tensor(id_list)\n",
    "        # sentence1 = tf.reshape(sentence1, [batch_size,8*MAX_BODY_LENGTH])\n",
    "        labels = tf.convert_to_tensor([np.array(data_batch_i['labels']) for _,data_batch_i in data_batch.iterrows()])\n",
    "        type_s1 = tf.zeros_like(sentence1)\n",
    "        yield ({'input_word_ids': sentence1,\n",
    "            'input_mask': tf.ones_like(sentence1),\n",
    "            'input_type_ids': type_s1,\n",
    "            'lens':len(data['arg_types']),\n",
    "            'id_list': id_list},labels)\n",
    "\n",
    "\n",
    "def gen():\n",
    "    for _, data_batch in data.groupby(np.arange(len(data))//batch_size):\n",
    "        if len(data_batch) < batch_size:\n",
    "            continue\n",
    "        ids = []\n",
    "\n",
    "        sentence1 = []\n",
    "        for _,data_batch_i in data_batch.iterrows():\n",
    "            print(type(data_batch_i['arg_types']))\n",
    "\n",
    "            id_list = []\n",
    "            sentence2 = np.array(transform(data_batch_i['body.1'])[:SEQ_LENGTH-1]+[3])\n",
    "            for label in eval(data_batch_i['arg_names']):\n",
    "                print(sentence2, label, np.where(sentence2 == subword_tokenizer.encode(label)[0])[0][0])\n",
    "                id_list.append( np.where(sentence2 == subword_tokenizer.encode(label)[0])[0][0])\n",
    "            sentence1.append(sentence2)\n",
    "        sentence1 = tf.ragged.constant(sentence1)\n",
    "        sentence1 = sentence1.to_tensor(default_value=0, shape=[batch_size, SEQ_LENGTH])\n",
    "        id_list =  tf.convert_to_tensor(id_list)\n",
    "        # sentence1 = tf.reshape(sentence1, [batch_size,8*MAX_BODY_LENGTH])\n",
    "        labels = tf.convert_to_tensor([np.array(data_batch_i['labels']) for _,data_batch_i in data_batch.iterrows()])\n",
    "        type_s1 = tf.zeros_like(sentence1)\n",
    "        yield ({'input_word_ids': sentence1,\n",
    "            'input_mask': tf.ones_like(sentence1),\n",
    "            'input_type_ids': type_s1,\n",
    "            'lens':len(data['arg_types']),\n",
    "            'id_list': id_list},labels)\n",
    "next(gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  \"\"\"\n",
    "    def main(task: Task) -> None:\n",
    "        task_tags = task.get('tags', [])\n",
    "\n",
    "        # Handle case when task has no context tags and no inbox tag.\n",
    "        if not any('@' in t for t in task_tags) and \"in\" not in task_tags:\n",
    "            task_tags.append('in')\n",
    "            task['tags'] = task_tags\n",
    "            logger.info(\"Task had no context tag - inbox tag has be applied\")\n",
    "\n",
    "        # Handle case when task has context tag and inbox tag.\n",
    "        elif any('@' in t for t in task_tags) and u'in' in task_tags:\n",
    "            task['tags'].remove('in')\n",
    "            logger.info(\"Task had both context and inbox tags - inbox tag has been removed.\")\"\"\"\n",
    "\n",
    "# a = '[CLS]'\n",
    "\n",
    "enc = code_to_subtokenized_sentences.code_to_cubert_sentences(\n",
    "        code=a,\n",
    "        initial_tokenizer=tokenizer,\n",
    "        subword_tokenizer=subword_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1115]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "subword_tokenizer.encode(tokenizer.tokenize('task')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['task_']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "subword_tokenizer.decode_list(subword_tokenizer.encode('task'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1115]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "subword_tokenizer.encode('task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['task', '___EOS___']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tokenizer.tokenize('task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    @staticmethod\n    def to_output(task: dict) -> str:\n        \"\"\"\n        Convert serialized task representation to Taskwarrior JSON hook output\n        format.\n\n        :param task: serialized task\n        :return: Taskwarrior JSON\n        \"\"\"\n        fields = Task.FIELDS.copy()\n\n        for k, v in task.items():\n            field_type = fields.get(k, None)\n            if isinstance(field_type, ArrayField) and not isinstance(field_type, AnnotationArrayField):\n                task[k] = ','.join(v)\n\n        return json.dumps(task, separators=(',', ':'))\n[    2    34    66   163  1527    15    43   253   432    20  1115    25\n   210    19  1716   148    25    15    34    45    86    35    26    63\n  3994    17 24350    17  1449    17  4070    17    75    17 28645 21947\n 26414   180    17  2058    17  8861    17   530    35    26    63   597\n    33    35    26    35    26    63    42   280    17  1449    42    17\n 24350    17  1449    35    26    63    42   393    42    17 28645 21947\n 26414   180    17  2058    35    26    63    95    15   504    24  3858\n    21 15458    21   878    20    19    15    10    82   341    16   337\n    68  1115    21   524    20    19    25    15    34    62  1502   142\n    24   504    21   157    20   341    16    70    19    15    46   472\n    20  1502   142    16  2009   256    19   202   126   472    20  1502\n   142    16 17844  2009   256    19    25    15    34   100  1115    31\n   341    30    24  1602    21   230    20   337    19    15    10     7\n     7    60   361    21  1520    20  1115    16 31172    24    20  1602\n    16  2710    19    19     7     7    15     3] task 10\n({'input_word_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[    2,    34,    66,   163,  1527,    15,    43,   253,   432,\n           20,  1115,    25,   210,    19,  1716,   148,    25,    15,\n           34,    45,    86,    35,    26,    63,  3994,    17, 24350,\n           17,  1449,    17,  4070,    17,    75,    17, 28645, 21947,\n        26414,   180,    17,  2058,    17,  8861,    17,   530,    35,\n           26,    63,   597,    33,    35,    26,    35,    26,    63,\n           42,   280,    17,  1449,    42,    17, 24350,    17,  1449,\n           35,    26,    63,    42,   393,    42,    17, 28645, 21947,\n        26414,   180,    17,  2058,    35,    26,    63,    95,    15,\n          504,    24,  3858,    21, 15458,    21,   878,    20,    19,\n           15,    10,    82,   341,    16,   337,    68,  1115,    21,\n          524,    20,    19,    25,    15,    34,    62,  1502,   142,\n           24,   504,    21,   157,    20,   341,    16,    70,    19,\n           15,    46,   472,    20,  1502,   142,    16,  2009,   256,\n           19,   202,   126,   472,    20,  1502,   142,    16, 17844,\n         2009,   256,    19,    25,    15,    34,   100,  1115,    31,\n          341,    30,    24,  1602,    21,   230,    20,   337,    19,\n           15,    10,     7,     7,    60,   361,    21,  1520,    20,\n         1115,    16, 31172,    24,    20,  1602,    16,  2710,    19,\n           19,     7,     7,    15,     3,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0]],\n      dtype=int32)>, 'input_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1]], dtype=int32)>, 'input_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0]], dtype=int32)>, 'lens': 125721, 'id_list': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([10], dtype=int32)>}, <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\narray([[14890,  7480,  7480,  7480,  7480,  7480,  7480,  7480,  7480,\n         7480]], dtype=int32)>)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 512, 1024), dtype=float32, numpy=\n",
       " array([[[-0.08364937,  0.14709947,  1.245698  , ...,  1.4123988 ,\n",
       "          -0.31031662,  0.3925744 ],\n",
       "         [ 1.8032562 ,  0.54278857,  1.4098477 , ..., -0.1873635 ,\n",
       "           0.7792913 , -1.2085233 ],\n",
       "         [ 1.607081  , -0.7228891 ,  1.1449388 , ..., -0.14121169,\n",
       "           0.94634205,  0.01603719],\n",
       "         ...,\n",
       "         [ 0.80791605, -1.0993781 , -0.22724296, ..., -0.4450596 ,\n",
       "           0.03087633,  0.5827752 ],\n",
       "         [-0.24425574, -0.0615343 ,  0.39945853, ...,  0.00753956,\n",
       "          -1.8997458 ,  0.20064537],\n",
       "         [ 0.44453552, -0.20257723,  0.507595  , ..., -1.4222213 ,\n",
       "          -0.37769067, -0.3870968 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
       " array([[ 0.84618807, -0.80333686, -0.9597301 , ...,  0.66008353,\n",
       "         -0.46292236,  0.99918175]], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "enc = next(gen())\n",
    "print(enc)\n",
    "bert_encoder(enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1115\ntf.Tensor(\n[ 0.8117472   0.45972186  1.5196487  ...  0.01904918 -1.066282\n  0.363116  ], shape=(1024,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(enc[0]['input_word_ids'].shape[0]):\n",
    "     print(enc[0]['input_word_ids'][i].numpy()[enc[0]['id_list'][i]])\n",
    "     print(bert_encoder(enc[0])[0][i][enc[0]['id_list'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['[CLS]_',\n",
       " '\\\\u\\\\u\\\\uINDENT\\\\u\\\\u\\\\u ',\n",
       " '   _',\n",
       " '@_',\n",
       " 'staticmethod_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " 'def_',\n",
       " 'to\\\\u^_',\n",
       " 'output_',\n",
       " '(_',\n",
       " 'task_',\n",
       " ':_',\n",
       " 'dict_',\n",
       " ')_',\n",
       " '->_',\n",
       " 'str_',\n",
       " ':_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uINDENT\\\\u\\\\u\\\\u ',\n",
       " '       _',\n",
       " '\"\"\"^_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '        ^_',\n",
       " 'Convert^_',\n",
       " ' ^_',\n",
       " 'serialized^_',\n",
       " ' ^_',\n",
       " 'task^_',\n",
       " ' ^_',\n",
       " 'representation^_',\n",
       " ' ^_',\n",
       " 'to^_',\n",
       " ' ^_',\n",
       " 'Tas',\n",
       " 'kwa',\n",
       " 'rri',\n",
       " 'or^_',\n",
       " ' ^_',\n",
       " 'JSON^_',\n",
       " ' ^_',\n",
       " 'hook^_',\n",
       " ' ^_',\n",
       " 'output^_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '        ^_',\n",
       " 'format^_',\n",
       " '.^_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '        ^_',\n",
       " ':^_',\n",
       " 'param^_',\n",
       " ' ^_',\n",
       " 'task^_',\n",
       " ':^_',\n",
       " ' ^_',\n",
       " 'serialized^_',\n",
       " ' ^_',\n",
       " 'task^_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '        ^_',\n",
       " ':^_',\n",
       " 'return^_',\n",
       " ':^_',\n",
       " ' ^_',\n",
       " 'Tas',\n",
       " 'kwa',\n",
       " 'rri',\n",
       " 'or^_',\n",
       " ' ^_',\n",
       " 'JSON^_',\n",
       " '\\\\u\\\\u\\\\uNLCHAR\\\\u\\\\u\\\\u^',\n",
       " '_',\n",
       " '        ^_',\n",
       " '\"\"\"_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " 'fields_',\n",
       " '=_',\n",
       " 'Task_',\n",
       " '._',\n",
       " 'FIELDS_',\n",
       " '._',\n",
       " 'copy_',\n",
       " '(_',\n",
       " ')_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uNL\\\\u\\\\u\\\\u_',\n",
       " 'for_',\n",
       " 'k_',\n",
       " ',_',\n",
       " 'v_',\n",
       " 'in_',\n",
       " 'task_',\n",
       " '._',\n",
       " 'items_',\n",
       " '(_',\n",
       " ')_',\n",
       " ':_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uINDENT\\\\u\\\\u\\\\u ',\n",
       " '           _',\n",
       " 'field\\\\u^_',\n",
       " 'type_',\n",
       " '=_',\n",
       " 'fields_',\n",
       " '._',\n",
       " 'get_',\n",
       " '(_',\n",
       " 'k_',\n",
       " ',_',\n",
       " 'None_',\n",
       " ')_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " 'if_',\n",
       " 'isinstance_',\n",
       " '(_',\n",
       " 'field\\\\u^_',\n",
       " 'type_',\n",
       " ',_',\n",
       " 'Array^_',\n",
       " 'Field_',\n",
       " ')_',\n",
       " 'and_',\n",
       " 'not_',\n",
       " 'isinstance_',\n",
       " '(_',\n",
       " 'field\\\\u^_',\n",
       " 'type_',\n",
       " ',_',\n",
       " 'Annotation^_',\n",
       " 'Array^_',\n",
       " 'Field_',\n",
       " ')_',\n",
       " ':_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uINDENT\\\\u\\\\u\\\\u ',\n",
       " '               _',\n",
       " 'task_',\n",
       " '[_',\n",
       " 'k_',\n",
       " ']_',\n",
       " '=_',\n",
       " \"','_\",\n",
       " '._',\n",
       " 'join_',\n",
       " '(_',\n",
       " 'v_',\n",
       " ')_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uNL\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uDEDENT\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uDEDENT\\\\u\\\\u\\\\u_',\n",
       " 'return_',\n",
       " 'json_',\n",
       " '._',\n",
       " 'dumps_',\n",
       " '(_',\n",
       " 'task_',\n",
       " ',_',\n",
       " 'separators_',\n",
       " '=_',\n",
       " '(_',\n",
       " \"','_\",\n",
       " ',_',\n",
       " \"':'_\",\n",
       " ')_',\n",
       " ')_',\n",
       " '\\\\u\\\\u\\\\uDEDENT\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uDEDENT\\\\u\\\\u\\\\u_',\n",
       " '\\\\u\\\\u\\\\uNEWLINE\\\\u\\\\u\\\\u_',\n",
       " '[SEP]_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_',\n",
       " '<pad>_']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "subword_tokenizer.decode_list(enc[0]['input_word_ids'].numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([10], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "enc[0]['id_list'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[127]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "subword_tokenizer.encode('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[708, 222, 1353]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "text = 'input_stream'\n",
    "subword_tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['input_^', 'stream', '___EOS___']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[690, 1353, 121]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "a = tokenizer.tokenize('input_stream')\n",
    "print(a)\n",
    "sum([subword_tokenizer.encode_without_tokenizing(i) for i in a],[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rgparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Task\n",
      "Task\n",
      "str\n",
      "List[Task]\n",
      "pandas.DataFrame\n",
      "List[Task]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "annofabapi.Resource\n",
      "Callable[..., Any]\n",
      "str\n",
      "str\n",
      "str\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "pandas.DataFrame\n",
      "List[Path]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "pandas.DataFrame\n",
      "TaskStatus\n",
      "Task\n",
      "List[Task]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "annofabapi.AnnofabApi\n",
      "List[Task]\n",
      "str\n",
      "str\n",
      "Dict[str, Any]\n",
      "str\n",
      "List[Task]\n",
      "Optional[Dict[str, Any]]\n",
      "Dict[str, Any]\n",
      "str\n",
      "pandas.DataFrame\n",
      "List[TaskHistory]\n",
      "List[TaskHistory]\n",
      "List[TaskHistory]\n",
      "List[TaskHistory]\n",
      "str\n",
      "List[Task]\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "List[str]\n",
      "pandas.Series\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "Dict[str, Any]\n",
      "pandas.Index\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "str\n",
      "pandas.DataFrame\n",
      "Inspection\n",
      "bool\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Inspection\n",
      "Optional[str]\n",
      "argparse.ArgumentParser\n",
      "argparse.Namespace\n",
      "argparse.Namespace\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Dict[str, Any]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Set[str]\n",
      "Set[str]\n",
      "Set[str]\n",
      "str\n",
      "str\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "List[Path]\n",
      "List[Path]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "int\n",
      "str\n",
      "Dict[str, Any]\n",
      "Dict[str, Any]\n",
      "List[Dict[str, Any]]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "pd.DataFrame\n",
      "list\n",
      "str\n",
      "annofabapi.Resource\n",
      "pd.DataFrame\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Task\n",
      "List[Task]\n",
      "List[Task]\n",
      "datetime.date\n",
      "int\n",
      "List[Task]\n",
      "Dict[str, Any]\n",
      "Dict[str, Any]\n",
      "str\n",
      "str\n",
      "Dict[str, float]\n",
      "List[TaskPhaseStatistics]\n",
      "List[Task]\n",
      "Dict[str, float]\n",
      "Dict[str, float]\n",
      "Dict[str, float]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "List[Path]\n",
      "List[Path]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "List[Dict[str, Any]]\n",
      "datetime.datetime\n",
      "argparse.Namespace\n",
      "datetime.timedelta\n",
      "List[List[Dict[str, Any]]]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "SimpleAnnotationParser\n",
      "bool\n",
      "Path\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "pandas.DataFrame\n",
      "Callable[..., Any]\n",
      "List[Dict[str, Any]]\n",
      "List[OrganizationMember]\n",
      "List[Project]\n",
      "Optional[Dict[str, Any]]\n",
      "Optional[Dict[str, Any]]\n",
      "Dict[str, Any]\n",
      "List[LaborWorktime]\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "str\n",
      "List[LaborAvailability]\n",
      "str\n",
      "List[LaborWorktime]\n",
      "pandas.DataFrame\n",
      "pandas.DataFrame\n",
      "pandas.Series\n",
      "pandas.DataFrame\n",
      "str\n",
      "str\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "TaskHistoryDict\n",
      "TaskHistoryDict\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "TaskHistoryDict\n",
      "TaskHistoryDict\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.Namespace\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Dict[str, Any]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "str\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "List[Inspection]\n",
      "List[Inspection]\n",
      "Inspection\n",
      "Inspection\n",
      "str\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.Namespace\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Optional[User]\n",
      "argparse.Namespace\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Path\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "Dict[str, Any]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "List[Task]\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "int\n",
      "List[Dict[str, Any]]\n",
      "pandas.DataFrame\n",
      "argparse.Namespace\n",
      "argparse.ArgumentParser\n",
      "argparse._SubParsersAction\n",
      "SimpleAnnotationParser\n",
      "SimpleAnnotationParser\n",
      "SimpleAnnotationParser\n",
      "SimpleAnnotationParser\n",
      "str\n",
      "CRecord\n",
      "CRecord\n",
      "List[SourceRecord]\n",
      "List[str]\n",
      "ChargeRecord\n",
      "ChargeRecord\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "List[SourceRecord]\n",
      "str\n",
      "str\n",
      "List[SourceRecord]\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "str\n",
      "dict\n",
      "Union[str, date, datetime, None]\n",
      "str\n",
      "dict\n",
      "str\n",
      "str\n",
      "dict\n",
      "List[Charge]\n",
      "Optional[Charge]\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "dict\n",
      "CRecord\n",
      "List[str]\n",
      "List[str]\n",
      "List[str]\n",
      "List[str]\n",
      "List[str]\n",
      "List[str]\n",
      "List[str]\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "str\n",
      "int\n",
      "str\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "str\n",
      "etree\n",
      "str\n",
      "etree\n",
      "etree\n",
      "etree\n",
      "str\n",
      "etree\n",
      "etree\n",
      "etree\n",
      "etree\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "str\n",
      "str\n",
      "Dict[int, Charge]\n",
      "str\n",
      "Dict[int, Union[str, int]]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "etree.Element\n",
      "etree.Element\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "Node\n",
      "Node\n",
      "etree.Element\n",
      "etree.Element\n",
      "etree.Element\n",
      "Union[BinaryIO, str]\n",
      "str\n",
      "Analysis\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "Person\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "Charge\n",
      "Charge\n",
      "Charge\n",
      "Union[CRecord, Charge]\n",
      "CRecord\n",
      "Charge\n",
      "Charge\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "Case\n",
      "Charge\n",
      "Charge\n",
      "CRecord\n",
      "Charge\n",
      "CRecord\n",
      "Charge\n",
      "Union[CRecord, Charge]\n",
      "Union[CRecord, Charge]\n",
      "Union[CRecord, Charge]\n",
      "Charge\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "Option[CRecord, Charge]\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "Case\n",
      "Charge\n",
      "Charge\n",
      "Case\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "CRecord\n",
      "Case\n",
      "CRecord\n",
      "Charge\n",
      "CRecord\n",
      "IRequest\n",
      "Folder\n",
      "IResource\n",
      "IResource\n",
      "List[List]\n",
      "Optional[IBaseObject]\n",
      "Optional[IBaseObject]\n",
      "typing.Union[str, list]\n",
      "List[Type[Interface]]\n",
      "Type[Interface]\n",
      "ResolvableType\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "IBaseObject\n",
      "IContainer\n",
      "IContainer\n",
      "IContainer\n",
      "IContainer\n",
      "IBaseObject\n",
      "IContainer\n",
      "IContainer\n",
      "ICatalogUtility\n",
      "IResource\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "IBaseObject\n",
      "IBaseObject\n",
      "str\n",
      "IBaseObject\n",
      "IRequest\n",
      "str\n",
      "IUploadDataManager\n",
      "int\n",
      "IDatabase\n",
      "Any\n",
      "IResource\n",
      "User\n",
      "User\n",
      "User\n",
      "User\n",
      "Group\n",
      "Group\n",
      "Group\n",
      "typing.Any\n",
      "bytes\n",
      "Exception\n",
      "str\n",
      "bool\n",
      "str\n",
      "str\n",
      "IBaseObject\n",
      "IBaseObject\n",
      "IBaseObject\n",
      "IBaseObject\n",
      "str\n",
      "str\n",
      "IBaseObject\n",
      "bool\n",
      "typing.Optional[ITransaction]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "dict\n",
      "\"\"\"PostgresqlStorage\"\"\"\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "Callable\n",
      "Callable[..., Coroutine[Any, Any, Any]]\n",
      "str\n",
      "str\n",
      "str\n",
      "IResource\n",
      "IResource\n",
      "IResource\n",
      "IResource\n",
      "IAsyncContainer\n",
      "IResource\n",
      "str\n",
      "Optional[IPrincipal]\n",
      "str\n",
      "int\n",
      "dict\n",
      "types.FunctionType\n",
      "typing.Union[str, bytes]\n",
      "str\n",
      "str\n",
      "dict\n",
      "str\n",
      "str\n",
      "str\n",
      "int\n",
      "str\n",
      "ResolvableType\n",
      "str\n",
      "str\n",
      "Dict[str, Any]\n",
      "Dict[str, Any]\n",
      "str\n",
      "Iterable[int]\n",
      "Sequence[int]\n",
      "Sequence[int]\n",
      "float\n",
      "int\n",
      "int\n",
      "bool\n",
      "int\n",
      "int\n",
      "int\n",
      "t.Union[bytes, str]\n",
      "socket.socket\n",
      "socket.socket\n",
      "socket.socket\n",
      "socket.socket\n",
      "socket.socket\n",
      "str\n",
      "int\n",
      "bool\n",
      "str\n",
      "t.Dict[str, t.Any]\n",
      "CGAPI\n",
      "int\n",
      "int\n",
      "int\n",
      "int\n",
      "int\n",
      "str\n",
      "bool\n",
      "argparse.Namespace\n",
      "t.Optional[str]\n",
      "t.Sequence[T]\n",
      "t.Dict[str, t.Any]\n",
      "t.Dict[str, t.Any]\n",
      "str\n",
      "str\n",
      "str\n",
      "T_CALL\n",
      "str\n",
      "str\n",
      "str\n",
      "bytes\n",
      "int\n",
      "Point\n",
      "bytes\n",
      "Point\n",
      "Point\n",
      "bytes\n",
      "bytes\n",
      "List[ModP]\n",
      "abjad.TweakInterface\n",
      "abjad.Ottava\n",
      "abjad.Ottava\n",
      "abjad.TweakInterface\n",
      "abjad.TweakInterface\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "int\n",
      "abjad.IndexedTweakManager\n",
      "abjad.IndexedTweakManager\n",
      "typing.Union[str, abjad.Dynamic]\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "str\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "str\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "typing.Union[str, typing.List]\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "typing.Union[str, typing.List]\n",
      "typing.Union[str, typing.List]\n",
      "abjad.IndexedTweakManager\n",
      "CommandTyping\n",
      "CommandTyping\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "_command_typing\n",
      "CommandTyping\n",
      "typing.Union[abjad.Tag, typing.List[abjad.Tag]]\n",
      "typing.Any\n",
      "abjad.DurationTyping\n",
      "typing.Any\n",
      "typing.Union[str, ide.Path, typing.Tuple[int, int, list]]\n",
      "typing.Any\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "typing.Union[str, abjad.Markup, commandclasses.IndicatorCommand]\n",
      "typing.Union[str, abjad.NamedPitch, abjad.StaffPosition, typing.List[abjad.\n",
      "    StaffPosition]]\n",
      "abjad.IndexedTweakManager\n",
      "str\n",
      "abjad.Instrument\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "typing.Union[str, abjad.Markup]\n",
      "typing.Union[str, indicators.Accelerando, indicators.Ritardando]\n",
      "ide.PartAssignment\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "rmakers.Command\n",
      "typing.Sequence[abjad.DurationTyping]\n",
      "typing.Sequence[abjad.DurationTyping]\n",
      "typing.Union[str, abjad.Selection]\n",
      "typing.Union[str, abjad.Selection]\n",
      "str\n",
      "abjad.Selection\n",
      "int\n",
      "int\n",
      "typing.List[int]\n",
      "typing.List[abjad.Number]\n",
      "typing.List[abjad.Number]\n",
      "typing.List[int]\n",
      "typing.List[int]\n",
      "abjad.Expression\n",
      "typing.Union[int, str, abjad.NamedPitch]\n",
      "typing.Union[int, abjad.StaffPosition]\n",
      "int\n",
      "typing.Sequence\n",
      "typing.Sequence[int]\n",
      "int\n",
      "int\n",
      "typing.Union[int, list, abjad.StaffPosition]\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "typing.List\n",
      "str\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "typing.Union[str, typing.List[str]]\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "typing.Union[int, str]\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "int\n",
      "typing.Union[str, typing.List[str]]\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "str\n",
      "str\n",
      "FigureMaker\n",
      "Assignment\n",
      "typing.Union[int, str, abjad.Pitch]\n",
      "abjad.Expression\n",
      "str\n",
      "typing.Sequence\n",
      "abjad.IntegerSequence\n",
      "typing.Sequence[int]\n",
      "typing.List[int]\n",
      "typing.List[int]\n",
      "typing.List[int]\n",
      "typing.List[int]\n",
      "typing.List[int]\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "str\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "typing.Union[str, abjad.Clef]\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.NumberPair\n",
      "typing.Union[str, abjad.Dynamic]\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "str\n",
      "int\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "bool\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "typings.HorizontalAlignmentTyping\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "str\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Number\n",
      "abjad.NumberPair\n",
      "abjad.Number\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.Expression\n",
      "abjad.NumberPair\n",
      "abjad.Markup\n",
      "abjad.Expression\n",
      "GithubConnection\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "nn.Module\n",
      "nn.Module\n",
      "HTTPStatus\n",
      "str\n",
      "MockFixture\n",
      "FlaskClient\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "List[Run]\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "K8SAPIClient\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "str\n",
      "V1Pod\n",
      "List[Run]\n",
      "MockFixture\n",
      "TensorboardManager\n",
      "TensorboardManager\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "str\n",
      "MockFixture\n",
      "MockFixture\n",
      "MockFixture\n",
      "TensorboardManager\n",
      "str\n",
      "Tuple[str, ...]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "dict\n",
      "str\n",
      "LogEntry\n",
      "str\n",
      "LogEntry\n",
      "LogEntry\n",
      "str\n",
      "str\n",
      "str\n",
      "List[str]\n",
      "str\n",
      "str\n",
      "(0.2)\n",
      "str\n",
      "dict\n",
      "dict\n",
      "str\n",
      "requests.Response\n",
      "str\n",
      "str\n",
      "str\n",
      "ExternalCliClient\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "Mocker\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "dict\n",
      "dict\n",
      "dict\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "List[dict]\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "List[str]\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "click.Context\n",
      "str\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "WorkflowViewMocks\n",
      "WorkflowViewMocks\n",
      "WorkflowListMocks\n",
      "WorkflowListMocks\n",
      "WorkflowCancelMocks\n",
      "WorkflowCancelMocks\n",
      "WorkflowCancelMocks\n",
      "WorkflowSubmitMocks\n",
      "WorkflowSubmitMocks\n",
      "WorkflowSubmitMocks\n",
      "WorkflowLogsMocks\n",
      "WorkflowLogsMocks\n",
      "WorkflowLogsMocks\n",
      "str\n",
      "str\n",
      "Generator[LogEntry, None, None]\n",
      "Generator[LogEntry, None, None]\n",
      "Experiment\n",
      "int\n",
      "int\n",
      "List[Run]\n",
      "Experiment\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "str\n",
      "Run\n",
      "click.Context\n",
      "str\n",
      "click.Context\n",
      "str\n",
      "click.Context\n",
      "LaunchPredictMocks\n",
      "LaunchPredictMocks\n",
      "LaunchPredictMocks\n",
      "LaunchPredictMocks\n",
      "LaunchPredictMocks\n",
      "StreamPredictMocks\n",
      "StreamPredictMocks\n",
      "StreamPredictMocks\n",
      "StreamPredictMocks\n",
      "StreamPredictMocks\n",
      "StreamPredictMocks\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "str\n",
      "Template\n",
      "str\n",
      "click.Context\n",
      "click.Context\n",
      "TemplateCopyMocks\n",
      "TemplateCopyMocks\n",
      "TemplateCopyMocks\n",
      "TemplateCopyMocks\n",
      "TemplateCopyMocks\n",
      "Template\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "List[Run]\n",
      "str\n",
      "Experiment\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "List[Tuple[str, str]]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "List[Tuple[str, str]]\n",
      "Tuple[str, ...]\n",
      "str\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "str\n",
      "ArgoWorkflow\n",
      "str\n",
      "str\n",
      "str\n",
      "List[Tuple[str, str]]\n",
      "List[Tuple[str, str]]\n",
      "click.Context\n",
      "Optional[str]\n",
      "click.Context\n",
      "click.Context\n",
      "click.Context\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "ViewMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "SubmitExperimentMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelExperimentMocks\n",
      "CancelMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "SubmitMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "InteractMocks\n",
      "click.Context\n",
      "str\n",
      "click.Context\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "click.Context\n",
      "click.Context\n",
      "UserCreationMocks\n",
      "UserCreationMocks\n",
      "UserCreationMocks\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "CreateUserMock\n",
      "click.Context\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "click.Context\n",
      "str\n",
      "click.Context\n",
      "ModelStatusMocks\n",
      "ModelStatusMocks\n",
      "ModelStatusMocks\n",
      "click.Context\n",
      "click.Context\n",
      "NAUTAAppNames\n",
      "List[str]\n",
      "List[str]\n",
      "int\n",
      "str\n",
      "timedelta\n",
      "V1Pod\n",
      "bool\n",
      "str\n",
      "LooseVersion\n",
      "str\n",
      "str\n",
      "str\n",
      "Dict[str, LooseVersion]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "Dict\n",
      "Dict\n",
      "Dict\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "Dict\n",
      "Dict\n",
      "str\n",
      "NAUTAAppNames\n",
      "str\n",
      "VerifyMocks\n",
      "VerifyMocks\n",
      "VerifyMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "CliStateMocks\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "NAUTAAppNames\n",
      "NAUTAAppNames\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "int\n",
      "int\n",
      "List[str]\n",
      "int\n",
      "List[str]\n",
      "List[str]\n",
      "int\n",
      "List[str]\n",
      "str\n",
      "str\n",
      "str\n",
      "NAUTAAppNames\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "bytes\n",
      "str\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CustomObjectsApi\n",
      "CoreV1Api\n",
      "ta.Dict[T, ta.Set[T]]\n",
      "ta.Iterable[ta.Any]\n",
      "ta.Dict[ta.Union[ta.Iterable[K], K], V]\n",
      "ta.Dict[ta.Any, ta.Any]\n",
      "T\n",
      "Item\n",
      "Readable\n",
      "ta.Iterable[T]\n",
      "int\n",
      "ta.Iterable[T]\n",
      "ta.Any\n",
      "str\n",
      "ta.Type\n",
      "ta.Any\n",
      "ta.Any\n",
      "weakref.ProxyType\n",
      "ta.Iterable[ta.Any]\n",
      "ta.Any\n",
      "str\n",
      "ta.Any\n",
      "ta.Callable[[], T]\n",
      "T\n",
      "ta.Any\n",
      "T\n",
      "ta.Union[Exception, ta.Type[Exception]]\n",
      "Self\n",
      "Self\n",
      "T\n",
      "T\n",
      "ta.Callable\n",
      "ContextWrappable\n",
      "contextvars.ContextVar[T]\n",
      "ta.Callable[[], ta.ContextManager[ta.Any]]\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "ta.Union[EnumT, str]\n",
      "int\n",
      "int\n",
      "int\n",
      "int\n",
      "datetime.timedelta\n",
      "datetime.date\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "ta.Callable[..., T]\n",
      "ta.Callable[..., ta.AsyncIterator[T]]\n",
      "ta.Callable[..., ta.AsyncIterator[T]]\n",
      "ta.Callable[..., ta.AsyncIterator[T]]\n",
      "ta.Sequence[concurrent.futures.Future]\n",
      "ta.Callable[..., T]\n",
      "ta.Callable[..., T]\n",
      "ta.Callable[..., T]\n",
      "type\n",
      "bool\n",
      "bool\n",
      "ta.Any\n",
      "T\n",
      "T\n",
      "T\n",
      "ta.Sized\n",
      "ta.Sized\n",
      "ta.Iterable[T]\n",
      "IH\n",
      "T\n",
      "T\n",
      "T\n",
      "ta.Any\n",
      "ta.Callable\n",
      "ta.Set[T]\n",
      "ta.Iterator[T]\n",
      "bool\n",
      "ta.Sequence[ta.List[T]]\n",
      "T\n",
      "T\n",
      "ta.Iterable[ta.Dict]\n",
      "inspect.FullArgSpec\n",
      "inspect.FullArgSpec\n",
      "int\n",
      "str\n",
      "ta.Union['signal.Handlers', ta.Callable[[int, ta.Any], None]]\n",
      "socket.socket\n",
      "int\n",
      "int\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "TypeLike\n",
      "TypeLike\n",
      "GenericAlias\n",
      "GenericAlias\n",
      "TypeLike\n",
      "TypeLike\n",
      "TypeLike\n",
      "TypeLike\n",
      "ta.Type\n",
      "ta.Type\n",
      "ta.Type\n",
      "ta.Type\n",
      "ta.Mapping[str, ta.Any]\n",
      "ta.Any\n",
      "Specable\n",
      "Specable\n",
      "Specable\n",
      "Specable\n",
      "Specable\n",
      "Spec\n",
      "Spec\n",
      "ta.Any\n",
      "str\n",
      "str\n",
      "ta.Iterable[ta.Tuple[str, str]]\n",
      "ta.Any\n",
      "int\n",
      "Function\n",
      "ta.Iterable[dis.Instruction]\n",
      "Frame\n",
      "\"\"\"Cache\"\"\"\n",
      "\"\"\"Cache\"\"\"\n",
      "weakref.ref\n",
      "ta.Tuple\n",
      "ta.Any\n",
      "ta.Union[Scope, str]\n",
      "Self\n",
      "int\n",
      "col.SortedMutableMapping\n",
      "ta.Callable[[], None]\n",
      "int\n",
      "str\n",
      "Name\n",
      "str\n",
      "str\n",
      "str\n",
      "str\n",
      "Request\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9d9f8fa05ba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arg_types'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \"\"\"\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2742\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m   2398\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2400\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[1;32m    131\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf-gpu/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmgr_locs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmgr_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _,i in data.iterrows():\n",
    "    print(i['arg_types'][0])"
   ]
  }
 ]
}